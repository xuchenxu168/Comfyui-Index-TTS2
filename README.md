# ğŸ™ï¸ ComfyUI IndexTTS2 Plugin

<div align="center">

![IndexTTS2 Logo](https://img.shields.io/badge/IndexTTS2-ComfyUI%20Plugin-blue?style=for-the-badge&logo=audio&logoColor=white)
![Version](https://img.shields.io/badge/Version-2.1-green?style=for-the-badge)
![License](https://img.shields.io/badge/License-Apache%202.0-orange?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-2.1%2B-red?style=for-the-badge&logo=pytorch)

**ğŸš€ The Most Advanced Text-to-Speech System for ComfyUI**

*Breakthrough emotionally expressive and duration-controlled autoregressive zero-shot text-to-speech synthesis*

[ğŸ¯ Quick Start](#-quick-start) â€¢ [ğŸ“¦ Installation](#-installation) â€¢ [ğŸ¨ Features](#-features) â€¢ [ğŸ“š Documentation](#-documentation) â€¢ [ğŸ¤ Community](#-community)

</div>

---

## ğŸŒŸ What Makes IndexTTS2 Special?

### ğŸ† Industry-First Innovations

<table>
<tr>
<td width="50%">

**ğŸ¯ Duration Control**
- First autoregressive TTS with precise timing control
- Speed adjustment (0.5x - 2.0x)
- Target duration specification
- Token-level precision control

</td>
<td width="50%">

**ğŸ­ Speaker-Emotion Disentanglement**
- Independent control of voice and emotion
- Cross-speaker emotion transfer
- Emotion preservation across speakers
- Advanced feature separation

</td>
</tr>
<tr>
<td width="50%">

**ğŸ¨ Multi-Modal Emotion Control**
- Audio-based emotion reference
- 8-dimensional emotion vectors
- Natural language emotion descriptions
- Real-time emotion adjustment
- **âš ï¸ Mode-specific configuration** (vector/text/audio)

</td>
<td width="50%">

**ğŸ—£ï¸ Multi-Speaker Conversations**
- 2-4 speaker support with individual emotions
- Classroom discussions, meetings, dialogues
- Modular emotion configuration system
- Custom speaker personality design
- **ğŸ†• Voice consistency control** for better speaker similarity
- **ğŸ†• Reference audio enhancement** for improved cloning quality

</td>
</tr>
</table>

### ğŸ”¥ Core Capabilities

- **ğŸ¤ Zero-Shot Speaker Cloning**: Clone any voice with just one audio sample
- **ğŸŒ Multi-Language Support**: Chinese, English, and seamless code-switching
- **âš¡ Real-Time Performance**: Optimized for fast, high-quality synthesis
- **ğŸ§  GPT Latent Integration**: Enhanced stability and naturalness
- **ğŸ›ï¸ Professional Control**: Prosody, timing, and emotion fine-tuning

## ğŸ“¦ Installation

<details>
<summary><b>ğŸš€ Quick Installation (Recommended)</b></summary>

### Prerequisites
- âœ… ComfyUI installed and working
- âœ… Python 3.8+ (3.10-3.11 recommended)
- âœ… CUDA-capable GPU (recommended for performance)
- âœ… 10GB+ free disk space

### One-Command Installation
```bash
# Clone and install everything
cd ComfyUI/custom_nodes
git clone https://github.com/your-repo/comfyui-index-tts2.git
cd comfyui-index-tts2
pip install -r requirements.txt
python download_models.py
```

</details>

<details>
<summary><b>ğŸ“‹ Detailed Installation Steps</b></summary>

### Step 1: Clone the Repository
```bash
cd ComfyUI/custom_nodes
git clone https://github.com/your-repo/comfyui-index-tts2.git
cd comfyui-index-tts2
```

### Step 2: Choose Your Installation Method

#### ğŸŒŸ Standard Installation (Recommended)
```bash
pip install -r requirements.txt
```

#### âš¡ æ™ºèƒ½å®‰è£… (æ¨è)
```bash
# ä½¿ç”¨æ™ºèƒ½å®‰è£…è„šæœ¬ï¼Œè‡ªåŠ¨å¤„ç†ä¾èµ–é—®é¢˜
python install_requirements.py
```

#### ğŸ“¦ æ‰‹åŠ¨å®‰è£…
```bash
# æ ‡å‡†å®‰è£…ï¼ˆä¸åŒ…å«å¯é€‰çš„ pyniniï¼‰
pip install -r requirements.txt

# ğŸªŸ Windows ç”¨æˆ·é¢å¤–ç¦åˆ©ï¼šå®‰è£… pynini é«˜çº§æ–‡æœ¬å¤„ç†
# Python 3.10 ç”¨æˆ·:
pip install pynini-wheel/pynini-2.1.6.post1-cp310-cp310-win_amd64.whl

# Python 3.11 ç”¨æˆ·:
pip install pynini-wheel/pynini-2.1.6.post1-cp311-cp311-win_amd64.whl

# Python 3.12 ç”¨æˆ·:
pip install pynini-wheel/pynini-2.1.6.post1-cp312-cp312-win_amd64.whl

# Python 3.13 ç”¨æˆ·:
pip install pynini-wheel/pynini-2.1.6.post1-cp313-cp313-win_amd64.whl
```



#### ğŸ Python 3.12+ Support
```bash
# Quick fix for Python 3.12
python quick_fix_py312.py

# Or full installation
python install_py312.py
```

### Step 3: Install Core Package
```bash
pip install -e index-tts/
```

### Step 4: Download Models

#### ğŸ”— Model Download Links

| Platform | Model | Download Link |
|----------|-------|---------------|
| **HuggingFace** | IndexTTS-2 | [ğŸ¤— IndexTTS-2](https://huggingface.co/IndexTeam/IndexTTS-2) |
| **ModelScope** | IndexTTS-2 | [ğŸ”— IndexTTS-2](https://modelscope.cn/models/IndexTeam/IndexTTS-2) |
| **HuggingFace** | IndexTTS-1.5 | [ğŸ¤— IndexTTS-1.5](https://huggingface.co/IndexTeam/IndexTTS-1.5) |
| **ModelScope** | IndexTTS-1.5 | [ğŸ”— IndexTTS-1.5](https://modelscope.cn/models/IndexTeam/IndexTTS-1.5) |
| **HuggingFace** | IndexTTS | [ğŸ¤— IndexTTS](https://huggingface.co/IndexTeam/IndexTTS) |
| **ModelScope** | IndexTTS | [ğŸ”— IndexTTS](https://modelscope.cn/models/IndexTeam/IndexTTS) |

#### ğŸ“ Model File Placement

**é‡è¦è¯´æ˜**: ä¸‹è½½æ•´ä¸ª IndexTTS-2 æ¨¡å‹æ–‡ä»¶å¤¹ï¼Œå¹¶å°†å…¶æ”¾å…¥ `Models/TTS/` ç›®å½•ä¸­ã€‚

```
ComfyUI/
â””â”€â”€ Models/
    â””â”€â”€ TTS/
        â””â”€â”€ IndexTTS-2/          # å°†ä¸‹è½½çš„å®Œæ•´æ¨¡å‹æ–‡ä»¶å¤¹æ”¾åœ¨è¿™é‡Œ
            â”œâ”€â”€ config.yaml
            â”œâ”€â”€ model.pth
            â””â”€â”€ [å…¶ä»–æ¨¡å‹æ–‡ä»¶...]
```

#### ğŸš€ Download Methods

```bash
# Automatic download (recommended)
python download_models.py

# Alternative methods:
# huggingface-cli download IndexTeam/IndexTTS-2 --local-dir=Models/TTS/IndexTTS-2
# modelscope download --model IndexTeam/IndexTTS-2 --local_dir Models/TTS/IndexTTS-2
```

### Step 5: Verify Installation
```bash
# Check transformers compatibility
python check_transformers_compatibility.py

# Or verify by loading a node in ComfyUI
# The nodes should appear in the IndexTTS2 category
```

### ğŸ”§ Troubleshooting Dependencies

If you encounter missing dependencies in different environments, you can check compatibility:

```bash
# Check transformers compatibility
python check_transformers_compatibility.py

# Install missing dependencies
pip install -r requirements.txt
```

**Common Missing Dependencies:**
- `descript-audiotools` - Required for audio processing (imports as `audiotools`)
- `json5` - Required for configuration files
- `transformers` - Required for model loading
- `einops` - Required for tensor operations
- `WeTextProcessing` - Optional for better text normalization (may fail on Windows)

**Quick Fix for Missing Dependencies:**
```bash
# Install all required dependencies
pip install -r requirements.txt

# For Python 3.12 environments
pip install -r requirements_py312.txt

# Install specific missing packages
pip install descript-audiotools json5 transformers einops

# Alternative audiotools installation (if pip fails)
pip install git+https://github.com/descriptinc/audiotools
```

**ğŸ”§ Special Notes for Dependencies:**

**For audiotools:**
If `pip install descript-audiotools` fails, try:
```bash
# Method 1: Install from GitHub
pip install git+https://github.com/descriptinc/audiotools

# Method 2: Clone and install manually
git clone https://github.com/descriptinc/audiotools
cd audiotools
pip install .
```

**For Text Normalization:**
IndexTTS2 now uses `wetext` for better text normalization - **no pynini dependency required!**

**ğŸ‰ wetext - The Perfect Solution**
- âœ… **wetext-0.1.0-py3-none-any.whl** - Universal Windows wheel available
- âœ… **No pynini dependency** - avoids all compilation issues
- âœ… **Same functionality** as WeTextProcessing but more reliable
- âœ… **Now included in requirements.txt** - automatically installed

**ğŸ” Common Issue: "Why does WeTextProcessing recompile pynini even when it's already installed?"**

This happens because:
1. **Version Pinning**: WeTextProcessing requires `pynini==2.1.6` specifically
2. **Dependency Resolution**: pip tries to install the exact version required
3. **Build Dependencies**: WeTextProcessing may specify build-time dependencies
4. **Platform Compatibility**: Your pynini wheel may not match WeTextProcessing's requirements

**ğŸš€ Solutions (if wetext installation fails):**

```bash
# Method 1: wetext is now in requirements.txt (automatic)
pip install -r requirements.txt

# Method 2: Manual wetext installation
pip install wetext

# Method 3: Alternative - WeTextProcessing (if you prefer)
pip install WeTextProcessing --only-binary=all

# Method 4: Use our complete solution installer
python install_text_processing_solution.py

# Method 5: Use fallback (always works)
# Skip text processing packages - IndexTTS2 works with basic fallback
```

**ğŸ‰ wetext is now the default!**
Since wetext is superior (no pynini dependency, same functionality), it's now included in requirements.txt and will be automatically installed.

**Note:** If WeTextProcessing installation fails, IndexTTS2 will automatically fall back to basic text processing. The plugin will still work, but text normalization quality may be reduced.

</details>

<details>
<summary><b>ğŸ”¤ Optional: Advanced Text Processing with Pynini</b></summary>

**Pynini** provides professional-grade text normalization for TTS applications, handling complex text formats like numbers, dates, currencies, and abbreviations.

#### ğŸŒŸ What Pynini Adds
- **ğŸ“ Phone Numbers**: `123-456-7890` â†’ `one two three four five six seven eight nine zero`
- **ğŸ’° Currency**: `$29.99` â†’ `twenty nine dollars and ninety nine cents`
- **ğŸ“… Dates**: `2024å¹´3æœˆ15æ—¥` â†’ `äºŒé›¶äºŒå››å¹´ä¸‰æœˆåäº”æ—¥`
- **ğŸ”¢ Numbers**: `Dr. Smith` â†’ `Doctor Smith`
- **ğŸŒ Mixed Languages**: Better Chinese-English text processing

#### ğŸ“¦ Installation by Platform

**ğŸ§ Linux (Recommended - Has Pre-compiled Wheels)**
```bash
# Easy installation with pre-compiled wheels (~150MB)
pip install pynini==2.1.6
```

**ğŸ macOS**
```bash
# Method 1: Conda (Recommended)
conda install -c conda-forge pynini=2.1.6

# Method 2: Pip (may require compilation)
pip install pynini==2.1.6
```

**ğŸªŸ Windows (ç°å·²ç®€åŒ–ï¼)**
```bash
# Method 1: ä½¿ç”¨é¡¹ç›®æä¾›çš„è½®å­æ–‡ä»¶ (æ¨èï¼Œæœ€ç®€å•)
# Python 3.10 ç”¨æˆ·:
pip install pynini-wheel/pynini-2.1.6.post1-cp310-cp310-win_amd64.whl

# Python 3.11 ç”¨æˆ·:
pip install pynini-wheel/pynini-2.1.6.post1-cp311-cp311-win_amd64.whl

# Python 3.12 ç”¨æˆ·:
pip install pynini-wheel/pynini-2.1.6.post1-cp312-cp312-win_amd64.whl

# Python 3.13 ç”¨æˆ·:
pip install pynini-wheel/pynini-2.1.6.post1-cp313-cp313-win_amd64.whl

# Method 2: ä½¿ç”¨è½®å­æ–‡ä»¶å¿«é€Ÿå®‰è£…è„šæœ¬ (æ¨è)
python install_pynini_wheel.py

# Method 3: ä½¿ç”¨å®Œæ•´å®‰è£…è„šæœ¬ (åŒ…å«å¤šç§æ–¹æ³•)
python install_pynini_windows.py

# Method 4: Conda (å¦‚æœå¯ç”¨)
conda install -c conda-forge pynini=2.1.6

# Method 5: è·³è¿‡å®‰è£… (æ¨èç»™å¤§å¤šæ•°ç”¨æˆ·)
# pynini æ˜¯å¯é€‰çš„ï¼ŒåŸºæœ¬åŠŸèƒ½ä¸å—å½±å“
```

**ğŸ‰ Windows ç”¨æˆ·ç¦éŸ³ï¼** æˆ‘ä»¬ç°åœ¨æä¾›äº†é¢„ç¼–è¯‘çš„ Windows è½®å­æ–‡ä»¶ï¼Œæ”¯æŒ Python 3.10-3.13ï¼Œæ— éœ€å¤æ‚çš„ç¼–è¯‘è¿‡ç¨‹ï¼

#### ğŸ“¦ Windows è½®å­æ–‡ä»¶è¯¦æƒ…

| Python ç‰ˆæœ¬ | è½®å­æ–‡ä»¶ | å¤§å° | æ”¯æŒæ¶æ„ |
|-------------|----------|------|----------|
| **Python 3.10** | `pynini-2.1.6.post1-cp310-cp310-win_amd64.whl` | ~150MB | Windows x64 |
| **Python 3.11** | `pynini-2.1.6.post1-cp311-cp311-win_amd64.whl` | ~150MB | Windows x64 |
| **Python 3.12** | `pynini-2.1.6.post1-cp312-cp312-win_amd64.whl` | ~150MB | Windows x64 |
| **Python 3.13** | `pynini-2.1.6.post1-cp313-cp313-win_amd64.whl` | ~150MB | Windows x64 |

**âœ… ä¼˜åŠ¿**:
- ğŸš€ **å³è£…å³ç”¨** - æ— éœ€ç¼–è¯‘ç¯å¢ƒ
- âš¡ **å¿«é€Ÿå®‰è£…** - å‡ ç§’é’Ÿå®Œæˆå®‰è£…
- ğŸ›¡ï¸ **ç¨³å®šå¯é ** - ç»è¿‡æµ‹è¯•çš„é¢„ç¼–è¯‘ç‰ˆæœ¬
- ğŸ”§ **é›¶é…ç½®** - æ— éœ€å®‰è£… Visual Studio æˆ–å…¶ä»–å·¥å…·
- ğŸ¯ **å…¨ç‰ˆæœ¬æ”¯æŒ** - è¦†ç›– Python 3.10-3.13

#### ğŸš€ Windows ç”¨æˆ·å¿«é€Ÿå®‰è£…æŒ‡å—

**æœ€ç®€å•çš„æ–¹æ³•**ï¼š
```bash
# ä¸€é”®å®‰è£… (è‡ªåŠ¨æ£€æµ‹ Python ç‰ˆæœ¬)
python install_pynini_wheel.py
```

**æ‰‹åŠ¨å®‰è£…**ï¼š
```bash
# æ£€æŸ¥æ‚¨çš„ Python ç‰ˆæœ¬
python --version

# æ ¹æ®ç‰ˆæœ¬é€‰æ‹©å¯¹åº”çš„è½®å­æ–‡ä»¶
pip install pynini-wheel/pynini-2.1.6.post1-cp3XX-cp3XX-win_amd64.whl
```

**æ”¯æŒçš„ Python ç‰ˆæœ¬**ï¼š
- âœ… Python 3.10
- âœ… Python 3.11
- âœ… Python 3.12
- âœ… Python 3.13

#### âš ï¸ Important Notes
- **ğŸ“¦ Large Package**: ~150MB download size
- **ğŸ§ Best Support**: Linux x86_64 with pre-compiled wheels
- **ğŸ”§ Compilation**: Other platforms may require C++ compiler
- **ğŸ¯ Optional**: Core TTS functionality works without Pynini
- **ğŸš€ Performance**: Significantly improves text processing quality

#### ğŸš€ Automated Installation Script
```bash
# Use our automated installer (recommended)
python install_pynini.py

# With testing
python install_pynini.py --test

# Force reinstall
python install_pynini.py --force
```

#### ğŸ§ª Manual Test Installation
```bash
# Verify Pynini installation
python -c "import pynini; print('âœ… Pynini installed successfully!')"

# Simple test
python -c "
import pynini
rule = pynini.string_map([('$', 'dollar')])
print('âœ… Pynini test passed!')
"
```

#### ğŸ¯ When to Install Pynini
**âœ… Recommended for:**
- Professional/commercial applications
- Complex text with numbers, dates, currencies
- Multi-language content (Chinese-English)
- High-quality text normalization needs

**âŒ Skip if:**
- Simple text-only content
- Quick prototyping/testing
- Limited storage/bandwidth
- Basic personal use

</details>

<details>
<summary><b>âš¡ DeepSpeed åŠ é€Ÿæ”¯æŒ (å¯é€‰)</b></summary>

**DeepSpeed** æ˜¯ä¸€ä¸ªæ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“ï¼Œå¯ä»¥æ˜¾è‘—æå‡ IndexTTS2 çš„è®­ç»ƒå’Œæ¨ç†æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§æ¨¡å‹å’Œå¤šGPUç¯å¢ƒä¸‹ã€‚

#### ğŸ¯ DeepSpeed çš„ä¼˜åŠ¿
- ğŸš€ **æ˜¾è‘—åŠ é€Ÿ** - æ¨ç†é€Ÿåº¦æå‡ 2-5 å€
- ğŸ’¾ **å†…å­˜ä¼˜åŒ–** - å‡å°‘ GPU å†…å­˜ä½¿ç”¨
- ğŸ”§ **è‡ªåŠ¨ä¼˜åŒ–** - æ™ºèƒ½æ¨¡å‹å¹¶è¡Œå’Œå†…å­˜ç®¡ç†
- ğŸ›ï¸ **çµæ´»é…ç½®** - æ”¯æŒå¤šç§ä¼˜åŒ–ç­–ç•¥

#### ğŸªŸ Windows å®‰è£…æ–¹æ³•

**âš ï¸ æ³¨æ„**: DeepSpeed å®˜æ–¹ä¸ç›´æ¥æ”¯æŒ Windowsï¼Œä½†ç¤¾åŒºæä¾›äº†é¢„ç¼–è¯‘è½®å­ã€‚

**ğŸ”— Windows è½®å­ä¸‹è½½åœ°å€**:
[https://github.com/6Morpheus6/deepspeed-windows-wheels/releases](https://github.com/6Morpheus6/deepspeed-windows-wheels/releases)

**å®‰è£…æ­¥éª¤**:
```bash
# 1. è®¿é—®ä¸Šè¿°é“¾æ¥ï¼Œé€‰æ‹©é€‚åˆæ‚¨ç¯å¢ƒçš„è½®å­æ–‡ä»¶
# 2. ä¸‹è½½å¯¹åº”çš„ .whl æ–‡ä»¶
# 3. ä½¿ç”¨ pip å®‰è£…ä¸‹è½½çš„è½®å­æ–‡ä»¶

# ç¤ºä¾‹ (è¯·æ ¹æ®å®é™…ä¸‹è½½çš„æ–‡ä»¶åè°ƒæ•´):
pip install deepspeed-0.12.6+cu118-cp311-cp311-win_amd64.whl
```

#### ğŸ“‹ ç‰ˆæœ¬é€‰æ‹©æŒ‡å—

| Python ç‰ˆæœ¬ | CUDA ç‰ˆæœ¬ | è½®å­æ–‡ä»¶ç¤ºä¾‹ |
|-------------|-----------|-------------|
| **Python 3.10** | CUDA 11.8 | `deepspeed-*-cp310-cp310-win_amd64.whl` |
| **Python 3.11** | CUDA 11.8 | `deepspeed-*-cp311-cp311-win_amd64.whl` |
| **Python 3.12** | CUDA 11.8 | `deepspeed-*-cp312-cp312-win_amd64.whl` |

**ğŸ’¡ é€‰æ‹©æç¤º**:
- æ£€æŸ¥æ‚¨çš„ Python ç‰ˆæœ¬: `python --version`
- æ£€æŸ¥æ‚¨çš„ CUDA ç‰ˆæœ¬: `nvidia-smi`
- é€‰æ‹©åŒ¹é…çš„è½®å­æ–‡ä»¶ä¸‹è½½

#### ğŸ§ Linux/macOS å®‰è£…
```bash
# Linux/macOS ç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨å®˜æ–¹ç‰ˆæœ¬
pip install deepspeed
```

#### ğŸ” éªŒè¯å®‰è£…
```bash
# æ£€æŸ¥ DeepSpeed æ˜¯å¦æ­£ç¡®å®‰è£…
python -c "import deepspeed; print('âœ… DeepSpeed version:', deepspeed.__version__)"
```

#### âš™ï¸ åœ¨ IndexTTS2 ä¸­ä½¿ç”¨
DeepSpeed å®‰è£…åä¼šè‡ªåŠ¨è¢« IndexTTS2 æ£€æµ‹å’Œä½¿ç”¨ï¼Œæ— éœ€é¢å¤–é…ç½®ã€‚

#### ğŸ’¡ ä½¿ç”¨å»ºè®®
- **ğŸ¯ æ¨èåœºæ™¯**: å¤§æ¨¡å‹æ¨ç†ã€æ‰¹é‡å¤„ç†ã€å¤šGPUç¯å¢ƒ
- **âš ï¸ æ³¨æ„äº‹é¡¹**: éœ€è¦å…¼å®¹çš„ CUDA ç‰ˆæœ¬å’Œè¶³å¤Ÿçš„ GPU å†…å­˜
- **ğŸ”§ æ•…éšœæ’é™¤**: å¦‚æœå®‰è£…å¤±è´¥ï¼Œå¯ä»¥è·³è¿‡ DeepSpeedï¼ŒåŸºæœ¬åŠŸèƒ½ä¸å—å½±å“
- **ğŸ“Š æ€§èƒ½æå‡**: åœ¨æ”¯æŒçš„ç¡¬ä»¶ä¸Šå¯è·å¾—æ˜¾è‘—çš„é€Ÿåº¦æå‡

</details>

<details>
<summary><b>ğŸµ Audio File Setup</b></summary>

### Smart Audio File Management

IndexTTS2 features **intelligent audio file scanning** across your entire ComfyUI installation:

#### ğŸ“ Supported Locations (Auto-Detected)
```
ComfyUI/
â”œâ”€â”€ input/audio/          ğŸŒŸ Highest Priority
â”œâ”€â”€ input/                ğŸŒŸ High Priority
â”œâ”€â”€ output/               âœ“ Supported
â”œâ”€â”€ audio/                âœ“ Supported
â”œâ”€â”€ user/audio/           âœ“ Supported
â””â”€â”€ [any other location]  âœ“ Supported
```

#### ğŸ¯ Two-Level Audio Selection System
1. **Level 1**: Select directory from dropdown
2. **Level 2**: Enter filename in text field

This eliminates long dropdown menus while supporting flexible file organization!

#### ğŸ“‹ Audio Requirements
- **Formats**: WAV, MP3, FLAC, OGG, M4A, AAC, WMA
- **Duration**: 3-10 seconds recommended
- **Quality**: Clear, noise-free, single speaker
- **Sample Rate**: 16kHz+ (22.05kHz optimal)

#### ğŸš€ Quick Setup
```bash
python setup_audio_files.py
python test_two_level_selection.py
```

</details>

### âœ… Verification

After installation, restart ComfyUI and look for **IndexTTS2** nodes in the node browser under the `IndexTTS2` category.

## ğŸ¯ Node Architecture

<div align="center">

### ğŸ§© Complete Node Ecosystem

</div>

<table>
<tr>
<th width="25%">Category</th>
<th width="25%">Node</th>
<th width="50%">Description</th>
</tr>

<tr>
<td rowspan="2"><b>ğŸ¤ Core TTS</b></td>
<td><code>IndexTTS2 Basic TTS</code></td>
<td>Foundation zero-shot speaker cloning with high-quality synthesis</td>
</tr>
<tr>
<td><code>IndexTTS2 Basic TTS V2</code></td>
<td>Enhanced version with two-level audio selection system</td>
</tr>

<tr>
<td rowspan="3"><b>ğŸ›ï¸ Control</b></td>
<td><code>IndexTTS2 Duration Control</code></td>
<td>Precise timing control: speed, duration, token-level precision</td>
</tr>
<tr>
<td><code>IndexTTS2 Emotion Control</code></td>
<td>Multi-modal emotion control: audio, vector, text descriptions</td>
</tr>
<tr>
<td><code>IndexTTS2 Advanced Control</code></td>
<td>Combined duration + emotion control with GPT latents</td>
</tr>

<tr>
<td rowspan="2"><b>ğŸ—£ï¸ Multi-Speaker</b></td>
<td><code>IndexTTS2 Multi-Talk</code></td>
<td>2-4 speaker conversations with individual emotion control</td>
</tr>
<tr>
<td><code>IndexTTS2 Speaker Emotion Config</code></td>
<td>Modular emotion configuration for complex workflows</td>
</tr>

<tr>
<td rowspan="3"><b>ğŸ”§ Utilities</b></td>
<td><code>IndexTTS2 Model Manager</code></td>
<td>Efficient model loading, caching, and memory management</td>
</tr>
<tr>
<td><code>IndexTTS2 Audio Utils</code></td>
<td>Audio processing, analysis, and quality enhancement</td>
</tr>
<tr>
<td><code>IndexTTS2 Audio Browser</code></td>
<td>Smart audio file discovery and management</td>
</tr>

</table>

### ğŸŒŸ Key Features by Node

<details>
<summary><b>ğŸ¤ IndexTTS2 Basic TTS</b></summary>

**Perfect for**: First-time users, simple voice cloning

**Features**:
- âœ… Zero-shot speaker cloning
- âœ… Multi-language support (Chinese, English, mixed)
- âœ… High-quality synthesis
- âœ… Configurable quality settings
- âœ… GPU/CPU optimization

**Inputs**: Text, speaker audio, output filename
**Outputs**: Synthesized audio, file path, synthesis info

</details>

<details>
<summary><b>ğŸ›ï¸ IndexTTS2 Duration Control</b></summary>

**Perfect for**: Precise timing requirements, video dubbing

**Features**:
- âœ… Speed control (0.5x - 2.0x)
- âœ… Target duration specification
- âœ… Token-level precision
- âœ… Prosody preservation
- âœ… Natural timing adaptation

**Control Modes**:
- `speed_control`: Adjust synthesis speed
- `token_control`: Specify exact token count
- `target_duration`: Set precise output duration
- `auto`: Natural duration with prosody preservation

</details>

<details>
<summary><b>ğŸ­ IndexTTS2 Emotion Control</b></summary>

**Perfect for**: Expressive speech, character voices

**Features**:
- âœ… Audio-based emotion reference
- âœ… 8-dimensional emotion vectors
- âœ… Natural language emotion descriptions
- âœ… Cross-speaker emotion transfer
- âœ… Emotion intensity adjustment

**Emotion Dimensions**:
- Happy, Angry, Sad, Fear, Hate, Low, Surprise, Neutral

**Control Methods**:
- `audio_prompt`: Use emotion reference audio
- `emotion_vector`: 8D emotion control
- `text_description`: Natural language emotions

</details>

<details>
<summary><b>ğŸ—£ï¸ IndexTTS2 Multi-Talk</b></summary>

**Perfect for**: Voice cloning, conversations, dialogues, classroom discussions

**Features**:
- âœ… 1-4 speaker support: 1=pure voice cloning, 2-4=conversation mode
- âœ… Individual emotion control per speaker
- âœ… Automatic conversation parsing (multi-speaker mode)
- âœ… Configurable silence intervals
- âœ… Modular emotion configuration

**Use Cases**:
- **Single Speaker**: Voice cloning, audiobooks, narration
- **Multi-Speaker**: Classroom discussions, business meetings
- **Character dialogues**: Theater, gaming, storytelling
- **Podcast conversations**: Multi-host discussions

</details>

<details>
<summary><b>ğŸµ IndexTTS2 Emotion Voice Multi-Talk (NEW!)</b></summary>

**Perfect for**: Voice cloning, emotion-driven conversations, character role-play

**Features**:
- âœ… 1-4 speaker support: 1=pure voice cloning, 2-4=conversation mode
- âœ… Direct audio input for emotion voice samples (no file paths needed!)
- âœ… Smart text parsing with emotion markers `[Happy]` (multi-speaker mode)
- âœ… Adjustable emotion intensity (0.0-2.0) per speaker
- âœ… Multiple emotion modes: emotion_voice, emotion_vector, auto
- âœ… High-performance synthesis with FP16/CUDA support

**Text Format**:

**Single Speaker Mode (num_speakers=1)**:
```
Hello everyone! This is a simple voice cloning example.
You can add emotion through the emotion voice input.
```

**Multi-Speaker Mode (num_speakers=2-4)**:
```
Speaker1: [Happy] Hello everyone! How are you doing today?
Speaker2: [Excited] I'm doing fantastic! Thanks for asking!
Speaker3: [Calm] I'm well, thank you. It's nice to see everyone.
```

**Emotion Control**:
- Connect audio loader nodes directly to emotion voice inputs
- Adjust emotion intensity with alpha values (0.0-2.0)
- Automatic emotion detection from text markers
- No need to manually input file paths - just connect audio nodes!

**Use Cases**:
- **Single Speaker**: Voice cloning, audiobooks, narration, emotional speech
- **Multi-Speaker**: Character role-playing, dramatic performances, theater
- **Educational**: Classroom discussions with emotional context
- **Entertainment**: Gaming, interactive storytelling, podcast creation

</details>

## ğŸš€ Quick Start

<div align="center">

### ğŸ¯ Get Started in 3 Minutes!

</div>

<details>
<summary><b>ğŸ¤ Basic Text-to-Speech (Beginner)</b></summary>

**Perfect for**: First-time users, simple voice cloning

### Step-by-Step Guide

1. **Add the node**: `IndexTTS2 Basic TTS`
2. **Set your text**:
   ```
   "Hello! This is my first IndexTTS2 synthesis."
   ```
3. **Choose speaker audio**: Use the two-level selection:
   - Directory: `input/audio`
   - File: `my_voice.wav`
4. **Set output**: `my_first_tts.wav`
5. **Execute**: Click "Queue Prompt"

### Expected Result
High-quality speech in your chosen speaker's voice!

</details>

<details>
<summary><b>ğŸ›ï¸ Duration-Controlled Synthesis (Intermediate)</b></summary>

**Perfect for**: Video dubbing, precise timing

### Step-by-Step Guide

1. **Add the node**: `IndexTTS2 Duration Control`
2. **Choose duration mode**:
   - `speed_control`: Adjust speed (0.8x for slower)
   - `target_duration`: Set exact duration (5.0 seconds)
3. **Configure text and audio** (same as basic)
4. **Execute and compare** timing

### Pro Tips
- Use `speed_control` for natural speed changes
- Use `target_duration` for exact timing requirements
- Enable `prosody_preservation` for better naturalness

</details>

<details>
<summary><b>ğŸ­ Emotion-Controlled Synthesis (Advanced)</b></summary>

**Perfect for**: Character voices, expressive speech

### Method 1: Emotion Vector Control
```
Happy: 0.8, Surprise: 0.2, Neutral: 0.0
Result: Excited, joyful speech
```

### Method 2: Text Description
```
Emotion Text: "devastated and heartbroken"
Result: Deep sadness and emotional pain
```

### Method 3: Audio Reference
```
Emotion Audio: "angry_reference.wav"
Result: Transfers anger from reference to your speaker
```

</details>

<details>
<summary><b>ğŸ—£ï¸ Multi-Speaker Conversations (Expert)</b></summary>

**Perfect for**: Dialogues, meetings, classroom discussions

### Quick Setup for 2-Speaker Dialogue

1. **Create emotion configs**:
   ```
   Speaker1 Config: Happy (0.8), Confident
   Speaker2 Config: Sad (0.6), Worried
   ```

2. **âš ï¸ IMPORTANT: Set correct emotion mode**:
   ```
   For emotion sliders (happy: 0.8) â†’ Use "emotion_vector" mode
   For text descriptions â†’ Use "text_description" mode
   ```

3. **Format conversation**:
   ```
   Speaker1: I'm so excited about this project!
   Speaker2: I'm worried we won't finish on time...
   Speaker1: Don't worry, we've got this!
   ```

4. **Connect everything**:
   - Audio inputs â†’ Speaker audio files
   - Emotion configs â†’ Multi-talk node
   - Set silence duration: 0.5 seconds

5. **Execute**: Get natural conversation with distinct emotions!

### ğŸ¯ Pro Example: Classroom Discussion
Check out `workflow-examples/classroom_4speakers_fixed.json` for a complete 4-speaker classroom discussion with Teacher, Student1, Student2, and Student3!

</details>

### ğŸ¨ Ready-to-Use Examples

| Example | Speakers | Complexity | Use Case |
|---------|----------|------------|----------|
| `simple_2speaker_example.json` | 2 | â­ | Basic dialogue |
| `classroom_4speakers_fixed.json` | 4 | â­â­â­ | Educational content |
| `business_meeting.json` | 3 | â­â­ | Professional scenarios |
| `mixed_emotion_modes.json` | 3 | â­â­â­ | Advanced emotion control |

### ğŸš€ Next Steps

1. **Try the examples**: Import a workflow from `workflow-examples/`
2. **Customize emotions**: Experiment with different emotion settings
3. **Create your content**: Build your own conversations and scenarios
4. **Join the community**: Share your creations and get help!

## ğŸ“‹ Parameter Reference

<div align="center">

### ğŸ›ï¸ Complete Parameter Guide

</div>

<details>
<summary><b>ğŸ“ Text & Audio Parameters</b></summary>

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `text` | String | Text to synthesize (Chinese, English, mixed) | `"Hello! ä½ å¥½ï¼"` |
| `speaker_audio` | Audio Path | Speaker reference audio file | `"input/audio/speaker.wav"` |
| `output_filename` | String | Generated audio filename | `"output.wav"` |
| `language` | Dropdown | Language mode | `auto`, `zh`, `en` |

</details>

<details>
<summary><b>â±ï¸ Duration Control Parameters</b></summary>

| Parameter | Type | Range | Description |
|-----------|------|-------|-------------|
| `duration_mode` | Dropdown | - | Control method |
| `speed_multiplier` | Float | 0.5 - 2.0 | Speed adjustment |
| `target_duration` | Float | 1.0 - 60.0 | Desired duration (seconds) |
| `token_count` | Integer | 10 - 1000 | Specific token count |
| `prosody_preservation` | Float | 0.0 - 1.0 | Maintain natural rhythm |

**Duration Modes**:
- `speed_control`: Adjust synthesis speed
- `token_control`: Specify exact tokens
- `target_duration`: Set precise duration
- `auto`: Natural duration

</details>

<details>
<summary><b>ğŸ­ Emotion Control Parameters</b></summary>

| Parameter | Type | Range | Description |
|-----------|------|-------|-------------|
| `emotion_mode` | Dropdown | - | Control method |
| `emotion_alpha` | Float | 0.0 - 2.0 | Emotion intensity |
| `emotion_audio` | Audio Path | - | Emotion reference audio |
| `emotion_text` | String | - | Natural language description |

**Emotion Vector (8 Dimensions)**:
- `happy` | Float | 0.0 - 1.0 | Joy, excitement
- `angry` | Float | 0.0 - 1.0 | Anger, frustration
- `sad` | Float | 0.0 - 1.0 | Sadness, melancholy
- `fear` | Float | 0.0 - 1.0 | Fear, anxiety
- `hate` | Float | 0.0 - 1.0 | Disgust, hatred
- `low` | Float | 0.0 - 1.0 | Low energy, calm
- `surprise` | Float | 0.0 - 1.0 | Surprise, wonder
- `neutral` | Float | 0.0 - 1.0 | Neutral, balanced

**Emotion Modes**:
- `audio_prompt`: Use emotion reference audio
- `emotion_vector`: 8-dimensional control
- `text_description`: Natural language
- `auto`: Automatic emotion detection

**âš ï¸ Important: Emotion Mode Configuration**
Make sure your `emotion_mode` setting matches your intended control method:
- If you set emotion vector values (happy, angry, etc.), use `emotion_vector` mode
- If you provide emotion text description, use `text_description` mode
- If you provide emotion audio file, use `audio_prompt` mode

**ğŸ”§ Common Issue**: Setting emotion vector values but leaving mode as `text_description` will result in neutral emotion output.

</details>

<details>
<summary><b>ğŸ”§ Advanced Settings</b></summary>

| Parameter | Type | Range | Description |
|-----------|------|-------|-------------|
| `use_gpt_latents` | Boolean | - | Enhanced stability |
| `stability_enhancement` | Boolean | - | Improve consistency |
| `clarity_boost` | Boolean | - | Enhance audio clarity |
| `fp16` | Boolean | - | Half-precision (faster) |
| `device` | Dropdown | - | GPU/CPU selection |
| `batch_size` | Integer | 1 - 8 | Batch processing size |

</details>

<details>
<summary><b>ğŸ—£ï¸ Multi-Speaker Parameters</b></summary>

| Parameter | Type | Range | Description |
|-----------|------|-------|-------------|
| `num_speakers` | Integer | 2 - 4 | Number of speakers |
| `conversation_text` | Text | - | Formatted dialogue |
| `silence_duration` | Float | 0.1 - 2.0 | Pause between speakers |
| **`voice_consistency`** | **Float** | **0.1 - 2.0** | **ğŸ†• Voice similarity to reference (higher = more similar)** |
| **`reference_boost`** | **Boolean** | **-** | **ğŸ†• Enable reference audio enhancement** |
| `auto_normalize` | Boolean | - | Volume normalization |
| `speaker_balance` | Boolean | - | Balance speaker volumes |

**Conversation Format**:
```
Speaker1: Hello everyone!
Speaker2: Hi there!
Speaker3: Good to see you all!
```

**ğŸ¯ Voice Consistency Tips**:
- **High Similarity (1.5-2.0)**: Professional dubbing, character voices
- **Balanced (1.0-1.3)**: General conversations, podcasts
- **Natural (0.8-1.0)**: Casual dialogues, creative content

</details>

<details>
<summary><b>ğŸ¯ Voice Consistency Improvement Guide</b></summary>

### ğŸ”§ New Features for Better Voice Similarity

#### 1. Voice Consistency Control
- **Parameter**: `voice_consistency` (0.1 - 2.0)
- **Default**: 1.0 (balanced)
- **Higher values**: More similar to reference audio
- **Lower values**: More natural variation

#### 2. Reference Audio Enhancement
- **Parameter**: `reference_boost` (True/False)
- **Function**: Automatically optimizes reference audio quality
- **Benefits**: Clearer voice cloning, reduced noise

### ğŸ“Š Recommended Settings

| Use Case | Voice Consistency | Reference Boost | Temperature | Top P |
|----------|------------------|-----------------|-------------|-------|
| **Professional Dubbing** | 1.6 | âœ… True | 0.6 | 0.8 |
| **Casual Conversation** | 1.1 | âœ… True | 0.7 | 0.9 |
| **Character Role-play** | 1.4 | âœ… True | 0.65 | 0.85 |
| **Natural Dialogue** | 1.0 | âŒ False | 0.8 | 0.9 |

### ğŸ¯ Troubleshooting Voice Issues

**Problem**: Generated voice differs too much from reference
**Solution**:
- Increase `voice_consistency` to 1.5-2.0
- Enable `reference_boost`
- Lower `temperature` to 0.5-0.6
- Use high-quality reference audio (2+ seconds, clear speech)

**Problem**: Voice sounds too mechanical
**Solution**:
- Decrease `voice_consistency` to 0.8-1.0
- Disable `reference_boost`
- Increase `temperature` to 0.8-1.0

### ğŸ“‹ Reference Audio Best Practices

**Quality Requirements**:
- **Duration**: 2-10 seconds
- **Format**: WAV/FLAC recommended
- **Content**: Clear speech, no background noise
- **Speaker**: Single person, consistent voice

**Optimization Tips**:
- Use speech with varied intonation
- Avoid music, echo, or noise
- Include different emotions/tones
- Ensure good audio quality (16kHz+)

For detailed guidance, see: [docs/voice_consistency_guide.md](docs/voice_consistency_guide.md)

</details>

## ğŸ¨ Usage Examples & Showcase

<div align="center">

### ğŸŒŸ Real-World Applications

</div>

<details>
<summary><b>ğŸ¤ Example 1: Basic Speaker Cloning</b></summary>

**Scenario**: Clone your voice for audiobook narration

```yaml
Input:
  Text: "Welcome to Chapter One of our exciting adventure story."
  Speaker Audio: "my_voice_sample.wav"
  Language: "auto"

Output:
  High-quality speech in your exact voice
  Perfect for: Audiobooks, podcasts, voice-overs
```

**Pro Tips**:
- Use 5-10 second clear audio samples
- Ensure single speaker, no background noise
- Test with different text lengths

</details>

<details>
<summary><b>ğŸ­ Example 2: Character Voice Creation</b></summary>

**Scenario**: Create distinct character voices for animation

```yaml
Character 1 - Hero:
  Text: "I will protect this city with my life!"
  Emotion Vector: {happy: 0.7, surprise: 0.2, neutral: 0.1}
  Result: Confident, heroic voice

Character 2 - Villain:
  Text: "You cannot stop my evil plan!"
  Emotion Vector: {angry: 0.8, hate: 0.3, neutral: 0.0}
  Result: Menacing, threatening voice
```

</details>

<details>
<summary><b>â±ï¸ Example 3: Video Dubbing with Precise Timing</b></summary>

**Scenario**: Dub a 5-second video clip exactly

```yaml
Input:
  Text: "This line must match the video timing perfectly."
  Duration Mode: "target_duration"
  Target Duration: 5.0
  Prosody Preservation: 0.8

Output:
  Exactly 5.0 seconds of natural-sounding speech
  Perfect for: Video dubbing, lip-sync, presentations
```

</details>

<details>
<summary><b>ğŸ—£ï¸ Example 4: Multi-Speaker Podcast</b></summary>

**Scenario**: Create a 3-person business podcast

```yaml
Host: "Welcome to TechTalk! Today we're discussing AI."
  Emotion: Professional, confident

Guest1: "Thanks for having me! I'm excited to share our research."
  Emotion: Enthusiastic, happy

Guest2: "The implications are concerning though..."
  Emotion: Thoughtful, slightly worried

Result: Natural conversation with distinct personalities
```

</details>

<details>
<summary><b>ğŸ“ Example 5: Educational Content</b></summary>

**Scenario**: Create engaging classroom discussion

```yaml
Teacher: "Today we'll explore quantum physics. Who knows about superposition?"
  Emotion: {happy: 0.3, neutral: 0.7} - Encouraging educator

Student1: "Oh! I know this! Particles can be in multiple states!"
  Emotion: {happy: 0.8, surprise: 0.2} - Excited learner

Student2: "I'm confused... how is that possible?"
  Emotion: {sad: 0.4, fear: 0.3, neutral: 0.3} - Uncertain

Student3: "Wait, does this mean reality isn't what we think?"
  Emotion Text: "philosophical and contemplative"
```

</details>

<details>
<summary><b>ğŸŒ Example 6: Cross-Language Content</b></summary>

**Scenario**: Bilingual customer service

```yaml
Text: "Hello! æ‚¨å¥½ï¼Welcome to our international support.
       How can I help you today? æˆ‘å¯ä»¥å¸®åŠ©æ‚¨å—ï¼Ÿ"

Features:
- Seamless language switching
- Maintains speaker identity across languages
- Natural pronunciation in both languages
```

</details>

### ğŸ¯ Use Case Gallery

| Industry | Application | IndexTTS2 Advantage |
|----------|-------------|-------------------|
| **ğŸ¬ Entertainment** | Character voices, dubbing | Emotion control + speaker cloning |
| **ğŸ“š Education** | Interactive lessons, audiobooks | Multi-speaker conversations |
| **ğŸ¢ Business** | Training materials, presentations | Professional quality + timing control |
| **ğŸ® Gaming** | Dynamic dialogue, NPCs | Real-time emotion adaptation |
| **â™¿ Accessibility** | Text-to-speech, voice restoration | Personalized voice synthesis |
| **ğŸ™ï¸ Content Creation** | Podcasts, YouTube, social media | Consistent voice across content |

## ğŸ”§ Troubleshooting & Support

<div align="center">

### ğŸ†˜ Common Issues & Solutions

</div>

<details>
<summary><b>âŒ Installation Issues</b></summary>

### âŒ Transformers å…¼å®¹æ€§é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: `cannot import name 'QuantizedCacheConfig' from 'transformers.cache_utils'`

**åŸå› **: transformers åº“ç‰ˆæœ¬ä¸å…¼å®¹

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥å…¼å®¹æ€§å’Œå½“å‰ç‰ˆæœ¬
python check_transformers_compatibility.py

# 2. å¦‚æœç‰ˆæœ¬è¿‡æ—§ï¼Œå°è¯•å‡çº§
pip install --upgrade transformers

# 3. å¦‚æœç‰ˆæœ¬è¿‡æ–°ï¼Œå¯èƒ½éœ€è¦é™çº§ (è°¨æ…æ“ä½œ)
# pip install transformers==4.36.2

# 4. é‡å¯ ComfyUI
```

### âŒ GenerationMode å±æ€§é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: `'NoneType' object has no attribute 'ASSISTED_GENERATION'`

**åŸå› **: GenerationMode ç±»æœªæ­£ç¡®å¯¼å…¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥å…¼å®¹æ€§
python check_transformers_compatibility.py

# 2. é‡å¯ ComfyUI (é‡è¦!)
# ä»£ç å·²åŒ…å«å…¼å®¹æ€§å¤„ç†ï¼Œé‡å¯ååº”è¯¥æ­£å¸¸å·¥ä½œ
```

**ğŸ’¡ æ³¨æ„**:
- ä¼˜å…ˆä¿æŒä¸ ComfyUI ç¯å¢ƒå…¼å®¹çš„ transformers ç‰ˆæœ¬
- å¦‚æœé—®é¢˜æŒç»­ï¼Œä»£ç å·²åŒ…å«å…¼å®¹æ€§å¤„ç†ï¼ŒåŸºæœ¬åŠŸèƒ½ä¸å—å½±å“
- é‡å¯ ComfyUI å¯ä»¥è§£å†³å¤§éƒ¨åˆ†å¯¼å…¥ç›¸å…³é—®é¢˜

### "No module named 'indextts'" Error
```bash
# Solution 1: Install the package
pip install -e index-tts/

# Solution 2: Check Python path
python -c "import sys; print(sys.path)"

# Solution 3: Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### Model Loading Fails
```bash
# Check model files
ls checkpoints/
# Should contain: config.yaml, model files

# Download models again
python download_models.py

# Check GPU memory
nvidia-smi  # For NVIDIA GPUs
```

### Python 3.12 Compatibility
```bash
# Quick fix
python quick_fix_py312.py

# Full installation
python install_py312.py

# Check compatibility
python check_all_dependencies.py
```

</details>

<details>
<summary><b>ğŸµ Audio Issues</b></summary>

### Audio File Not Found
- âœ… Use the two-level audio selection system
- âœ… Check file exists in selected directory
- âœ… Verify supported formats: WAV, MP3, FLAC, OGG
- âœ… Test with absolute paths if needed

### Poor Audio Quality
**Speaker Audio Requirements**:
- ğŸ“ Duration: 3-10 seconds
- ğŸ”Š Quality: Clear, noise-free
- ğŸ‘¤ Content: Single speaker only
- ğŸ“Š Sample Rate: 16kHz+ (22.05kHz optimal)

**Quality Improvement Tips**:
```bash
# Test audio quality
python test_audio_quality.py your_audio.wav

# Audio preprocessing
python fix_audio_quality.py input.wav output.wav
```

</details>

<details>
<summary><b>âš¡ Performance Issues</b></summary>

### Memory Optimization
```python
# Use Model Manager for efficient caching
Model Manager â†’ Enable FP16 â†’ Set device to GPU

# Clear cache when needed
Model Manager â†’ Clear Cache
```

### Speed Optimization
- ğŸš€ Enable CUDA if available
- âš¡ Use FP16 precision
- ğŸ§  Cache models with Model Manager
- ğŸ“¦ Use batch processing for multiple files

### GPU Memory Issues
```bash
# Check GPU memory
nvidia-smi

# Reduce memory usage
- Enable FP16
- Reduce batch size
- Use CPU for large models
```

</details>

<details>
<summary><b>ğŸ­ Emotion Control Issues</b></summary>

### âŒ Problem: Emotion Vector Values Ignored (Shows "neutral: 1.0")

**Symptoms**:
- You set `happy: 0.8` in emotion config
- Console shows `neutral: 1.0` instead
- Generated voice sounds neutral despite emotion settings

**Root Cause**: Emotion mode mismatch

**âœ… Solution**:
1. **Check your emotion config node**
2. **Change `emotion_mode` from `text_description` to `emotion_vector`**
3. **Reconnect the emotion config to multi-talk node**
4. **Re-run the workflow**

**Step-by-Step Fix**:
```
1. Click on your Speaker Emotion Config node
2. Find the "emotion_mode" dropdown
3. Change from "text_description" â†’ "emotion_vector"
4. Verify your emotion values are set (e.g., happy: 0.8)
5. Make sure "enabled" is checked (True)
6. Execute workflow again
```

### âŒ Problem: Wrong Emotion Mode Selected

**Common Mistakes**:
- Setting emotion vector values but using `text_description` mode
- Providing emotion text but using `emotion_vector` mode
- Using `audio_prompt` mode without emotion audio file

**âœ… Mode Selection Guide**:
| Your Input | Correct Mode | Example |
|------------|--------------|---------|
| **Emotion sliders** (happy: 0.8, etc.) | `emotion_vector` | happy: 0.8, angry: 0.2 |
| **Text description** | `text_description` | "excited and joyful" |
| **Audio file** | `audio_prompt` | emotion_audio.wav |
| **Auto-detect** | `auto` | Let system decide |

### âŒ Problem: Emotions Not Working
1. **Check emotion config enabled**: `enabled = true`
2. **Verify connections**: Emotion config â†’ Multi-talk node
3. **Test emotion values**: At least one dimension > 0
4. **Check emotion mode**: Matches your input type

### âŒ Problem: Emotion Vector All Zeros
```python
# System auto-fix: Sets neutral = 0.1
# Manual fix: Set at least one emotion > 0
happy: 0.5, neutral: 0.0  # Good
all zeros â†’ neutral: 0.1  # Auto-corrected
```

### ğŸ” Debug Console Messages

**What to Look For**:
```bash
# âœ… Correct (emotion_vector mode):
[MultiTalk] Speaker1 emotion mode: emotion_vector
[MultiTalk] Speaker1 emotions: Happy: 0.80

# âŒ Wrong (text_description mode with no text):
[MultiTalk] Speaker1 emotion mode: text_description
{'neutral': 1.0}  # Falls back to neutral
```

**Expected Console Output**:
```bash
# When working correctly:
[MultiTalk] Emotion mode: emotion_vector
['æ„¤æ€’:0.00', 'é«˜å…´:0.80', 'ææƒ§:0.00', 'åæ„Ÿ:0.00', 'æ‚²ä¼¤:0.00', 'ä½è½:0.00', 'æƒŠè®¶:0.00', 'è‡ªç„¶:0.20']
{'happy': 0.8, 'angry': 0.0, 'sad': 0.0, 'fear': 0.0, 'hate': 0.0, 'low': 0.0, 'surprise': 0.0, 'neutral': 0.2}
Use the specified emotion vector
```

</details>

### ğŸ” Diagnostic Tools

| Tool | Purpose | Command |
|------|---------|---------|
| **Dependency Checker** | Verify all packages | `python check_all_dependencies.py` |
| **Audio Tester** | Test audio files | `python test_audio_quality.py` |
| **Model Validator** | Check model files | `python test_model_loading.py` |
| **System Info** | Hardware compatibility | `python system_info.py` |

### ğŸ“ Getting Help

<table>
<tr>
<td width="50%">

**ğŸ› Bug Reports**
- GitHub Issues
- Include error logs
- System information
- Reproduction steps

</td>
<td width="50%">

**ğŸ’¬ Community Support**
- Discord: ComfyUI community
- Reddit: r/ComfyUI
- GitHub Discussions
- Documentation wiki

</td>
</tr>
</table>

### ğŸš€ Performance Benchmarks

| Hardware | Speed | Memory | Quality |
|----------|-------|--------|---------|
| **RTX 4090** | 10x real-time | 8GB | Excellent |
| **RTX 3080** | 6x real-time | 6GB | Excellent |
| **RTX 2080** | 3x real-time | 4GB | Very Good |
| **CPU Only** | 0.5x real-time | 8GB RAM | Good |

## ğŸ“š Documentation & Resources

<div align="center">

### ğŸ“– Complete Documentation Library

</div>

<details>
<summary><b>ğŸ“‹ Technical Documentation</b></summary>

### Core Documentation Files
- ğŸ“˜ **[FEATURES.md](FEATURES.md)** - Complete feature overview
- ğŸ”§ **[DEPENDENCY_INSTALLATION_GUIDE.md](DEPENDENCY_INSTALLATION_GUIDE.md)** - Installation guide
- ğŸ­ **[MODULAR_EMOTION_CONTROL_GUIDE.md](MODULAR_EMOTION_CONTROL_GUIDE.md)** - Emotion control
- ğŸ—£ï¸ **[MULTI_TALK_GUIDE.md](MULTI_TALK_GUIDE.md)** - Multi-speaker conversations
- ğŸµ **[docs/classroom_discussion_guide.md](docs/classroom_discussion_guide.md)** - Classroom scenarios

### Workflow Examples
- ğŸ“ **[workflow-examples/](workflow-examples/)** - Ready-to-use workflows
- ğŸš€ **[workflow-examples/QUICK_START.md](workflow-examples/QUICK_START.md)** - Quick start guide
- ğŸ“– **[workflow-examples/README.md](workflow-examples/README.md)** - Example documentation

</details>

<details>
<summary><b>ğŸ”¬ Technical Specifications</b></summary>

### Model Architecture
**IndexTTS2** is built on cutting-edge autoregressive transformer technology:

- ğŸ§  **Base Architecture**: GPT-style autoregressive transformer
- ğŸ¯ **Training Paradigm**: Three-stage training with GPT latents
- ğŸ“ **Context Length**: Up to 2048 tokens
- ğŸ”Š **Sample Rate**: 22.05 kHz (configurable)
- ğŸ’¾ **Model Size**: ~1.5GB (optimized)

### Key Innovations
1. **ğŸ›ï¸ Duration Control**: First autoregressive TTS with precise timing
2. **ğŸ­ Emotion Disentanglement**: Independent voice and emotion control
3. **ğŸŒ Multi-Modal Control**: Audio, vector, and text emotion input
4. **âš¡ GPT Latents**: Enhanced stability and naturalness

### Performance Specifications
- **ğŸš€ Synthesis Speed**: Real-time to 10x faster
- **ğŸ’¾ Memory Usage**: 4-8GB GPU (with optimization)
- **ğŸ¯ Quality**: High speaker similarity, natural prosody
- **â±ï¸ Latency**: Sub-second for short texts

</details>

<details>
<summary><b>ğŸ› ï¸ Development Resources</b></summary>

### Testing & Validation Tools
```bash
# Comprehensive dependency check
python check_all_dependencies.py

# Audio quality testing
python test_audio_quality.py

# Model validation
python test_model_loading.py

# Workflow validation
python workflow-examples/validate_workflows.py
```

### Development Scripts
- ğŸ”§ **Setup**: `setup_audio_files.py`, `download_models.py`
- ğŸ§ª **Testing**: `test_*.py` files for various components
- ğŸ” **Debugging**: `debug_*.py` files for troubleshooting
- âš¡ **Optimization**: `fix_*.py` files for performance

</details>

## ğŸ¤ Community & Contributing

<div align="center">

### ğŸŒŸ Join Our Growing Community!

</div>

<table>
<tr>
<td width="50%">

**ğŸ¤ How to Contribute**
1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch
3. âœ¨ Make your improvements
4. ğŸ§ª Add tests if applicable
5. ğŸ“¤ Submit a pull request

**ğŸ¯ Contribution Areas**
- ğŸ› Bug fixes and improvements
- ğŸ“š Documentation enhancements
- ğŸ¨ New workflow examples
- ğŸ”§ Performance optimizations
- ğŸŒ Translations and localization

</td>
<td width="50%">

**ğŸ’¬ Community Channels**
- ğŸ™ **GitHub**: Issues, discussions, PRs
- ğŸ’¬ **Discord**: ComfyUI community server
- ğŸ“± **Reddit**: r/ComfyUI subreddit
- ğŸ“§ **Email**: For commercial inquiries
- ğŸ“– **Wiki**: Community documentation

**ğŸ† Recognition**
- Contributors listed in CONTRIBUTORS.md
- Special thanks in release notes
- Community showcase features

</td>
</tr>
</table>

## ğŸ“„ License & Legal

<div align="center">

**ğŸ“œ Apache 2.0 License**

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.

</div>

### ğŸ™ Acknowledgments

<table>
<tr>
<td width="33%">

**ğŸ”¬ Research Team**
- IndexTTS2 research team
- Original model developers
- Academic contributors

</td>
<td width="33%">

**ğŸ› ï¸ Technical Community**
- ComfyUI framework team
- PyTorch community
- Open source contributors

</td>
<td width="33%">

**ğŸ‘¥ User Community**
- Beta testers
- Documentation contributors
- Workflow creators

</td>
</tr>
</table>

---

## ğŸš€ å¼€å‘ä¸å‘å¸ƒ

### GitHub Actions å·¥ä½œæµ

æœ¬é¡¹ç›®åŒ…å«å®Œæ•´çš„ CI/CD æµæ°´çº¿ï¼š

#### ğŸ“‹ **æŒç»­é›†æˆ (CI)**
- **è§¦å‘æ¡ä»¶**: æ¨é€åˆ° main/develop åˆ†æ”¯ï¼ŒPull Request
- **æµ‹è¯•ç¯å¢ƒ**: Ubuntu + Windows, Python 3.10/3.11
- **æ£€æŸ¥å†…å®¹**:
  - âœ… Python è¯­æ³•éªŒè¯
  - âœ… ä¾èµ–é¡¹å®‰è£…æµ‹è¯•
  - âœ… æ¨¡å—å¯¼å…¥æµ‹è¯•
  - âœ… ä»£ç æ ¼å¼æ£€æŸ¥ (black, flake8, isort)
  - âœ… å®‰å…¨æ‰«æ (bandit, safety)
  - âœ… JSON å·¥ä½œæµéªŒè¯

#### ğŸš€ **è‡ªåŠ¨å‘å¸ƒ (Publish)**
- **è§¦å‘æ¡ä»¶**: æ¨é€ç‰ˆæœ¬æ ‡ç­¾ (v*)ï¼Œæ‰‹åŠ¨è§¦å‘
- **å‘å¸ƒå†…å®¹**:
  - ğŸ“¦ åˆ›å»º GitHub Release
  - ğŸ“„ è‡ªåŠ¨ç”Ÿæˆ Changelog
  - ğŸ—œï¸ æ‰“åŒ…æºç  (tar.gz + zip)
  - ğŸ“‹ ç”Ÿæˆ ComfyUI Manager æäº¤ä¿¡æ¯

### ğŸ·ï¸ **å‘å¸ƒæ–°ç‰ˆæœ¬**

1. **åˆ›å»ºç‰ˆæœ¬æ ‡ç­¾**:
   ```bash
   git tag v1.0.0
   git push origin v1.0.0
   ```

2. **è‡ªåŠ¨å‘å¸ƒæµç¨‹**:
   - GitHub Actions è‡ªåŠ¨æ„å»ºå’Œæµ‹è¯•
   - åˆ›å»º GitHub Release
   - ç”Ÿæˆä¸‹è½½åŒ…
   - é€šçŸ¥ ComfyUI Manager

3. **æ‰‹åŠ¨è§¦å‘**:
   - è®¿é—® GitHub Actions é¡µé¢
   - é€‰æ‹© "Publish ComfyUI IndexTTS2" å·¥ä½œæµ
   - ç‚¹å‡» "Run workflow"

### ğŸ”§ **å¼€å‘è´¡çŒ®**

æ¬¢è¿æäº¤ Pull Requestï¼è¯·ç¡®ä¿ï¼š
- ä»£ç é€šè¿‡æ‰€æœ‰ CI æ£€æŸ¥
- éµå¾ªé¡¹ç›®ä»£ç é£æ ¼
- æ·»åŠ é€‚å½“çš„æµ‹è¯•å’Œæ–‡æ¡£

---

<div align="center">

### ğŸš€ Ready to Create Amazing Voice Content?

**[â¬†ï¸ Back to Top](#-comfyui-indextts2-plugin)** â€¢ **[ğŸ“¦ Install Now](#-installation)** â€¢ **[ğŸ¯ Quick Start](#-quick-start)** â€¢ **[ğŸ¤ Join Community](#-community--contributing)**

---

**ğŸ™ï¸ IndexTTS2 ComfyUI Plugin** - *Bringing Professional Voice Synthesis to Everyone*

![Made with â¤ï¸](https://img.shields.io/badge/Made%20with-â¤ï¸-red?style=for-the-badge)
![Open Source](https://img.shields.io/badge/Open%20Source-ğŸ’š-green?style=for-the-badge)
![Community Driven](https://img.shields.io/badge/Community%20Driven-ğŸ¤-blue?style=for-the-badge)

</div>
