# IndexTTS2 Basic TTS Node
# IndexTTS2 åŸºç¡€è¯­éŸ³åˆæˆèŠ‚ç‚¹

import os
import torch
import numpy as np
from typing import Optional, Tuple, Any
import folder_paths

# å¯¼å…¥éŸ³é¢‘æµè§ˆå™¨ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
try:
    from ..audio_browser import get_all_audio_files
    AUDIO_BROWSER_AVAILABLE = True
except ImportError:
    AUDIO_BROWSER_AVAILABLE = False
    print("éŸ³é¢‘æµè§ˆå™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨åŸºç¡€æ‰«æåŠŸèƒ½")

# å¯¼å…¥ç›®å½•éŸ³é¢‘æµè§ˆå™¨
try:
    from ..directory_audio_browser import (
        get_audio_directory_choices,
        get_audio_file_choices,
        get_full_audio_path
    )
    DIRECTORY_BROWSER_AVAILABLE = True
except ImportError:
    DIRECTORY_BROWSER_AVAILABLE = False
    print("ç›®å½•éŸ³é¢‘æµè§ˆå™¨æ¨¡å—æœªæ‰¾åˆ°")

# æ·»åŠ éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„åˆ°ComfyUI
# Add audio folder paths to ComfyUI
def get_audio_files():
    """è·å–å¯ç”¨çš„éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨"""

    # å¦‚æœé«˜çº§éŸ³é¢‘æµè§ˆå™¨å¯ç”¨ï¼Œä½¿ç”¨å®ƒ
    if AUDIO_BROWSER_AVAILABLE:
        try:
            audio_files = get_all_audio_files(use_cache=True, max_files=100)

            # å¦‚æœæ‰¾åˆ°äº†éŸ³é¢‘æ–‡ä»¶ï¼Œç›´æ¥è¿”å›
            if audio_files and len(audio_files) > 0:
                return audio_files
        except Exception as e:
            print(f"é«˜çº§éŸ³é¢‘æµè§ˆå™¨å‡ºé”™ï¼Œä½¿ç”¨åŸºç¡€æ‰«æ: {e}")

    # ä½¿ç”¨åŸºç¡€æ‰«æåŠŸèƒ½ä½œä¸ºåå¤‡
    audio_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a']
    audio_files = []

    # å®šä¹‰è¦æ‰«æçš„ç›®å½•åˆ—è¡¨
    scan_dirs = [
        folder_paths.input_directory,  # inputç›®å½•
        os.path.join(folder_paths.input_directory, "audio"),
        os.path.join(folder_paths.base_path, "input", "audio"),
        os.path.join(folder_paths.base_path, "audio"),
        os.path.join(folder_paths.base_path, "custom_nodes", "comfyui-index-tts2", "audio"),
        os.path.join(folder_paths.base_path, "custom_nodes", "comfyui-index-tts2", "examples"),
    ]

    def scan_directory(directory):
        """æ‰«æç›®å½•ä¸­çš„éŸ³é¢‘æ–‡ä»¶"""
        if not os.path.exists(directory):
            return

        try:
            for item in os.listdir(directory):
                item_path = os.path.join(directory, item)

                if os.path.isfile(item_path):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯éŸ³é¢‘æ–‡ä»¶
                    if any(item.lower().endswith(ext) for ext in audio_extensions):
                        try:
                            relative_path = os.path.relpath(item_path, folder_paths.base_path)
                            audio_files.append(relative_path)
                        except ValueError:
                            audio_files.append(item_path)

        except (PermissionError, OSError):
            pass

    # æ‰«ææ‰€æœ‰æŒ‡å®šç›®å½•
    for scan_dir in scan_dirs:
        scan_directory(scan_dir)

    # å»é‡å¹¶æ’åº
    audio_files = list(set(audio_files))
    audio_files.sort()

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œæ·»åŠ æç¤ºä¿¡æ¯
    if not audio_files:
        audio_files = [
            "ğŸ” æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ / No audio files found",
            "ğŸ“ è¯·å°†éŸ³é¢‘æ–‡ä»¶æ”¾å…¥ input/audio/ ç›®å½•",
            "ğŸ“ Please put audio files in input/audio/ directory",
            "ğŸ”„ ç„¶åé‡æ–°åŠ è½½èŠ‚ç‚¹ / Then reload the node"
        ]

    return audio_files

class IndexTTS2BasicNode:
    """
    IndexTTS2 åŸºç¡€è¯­éŸ³åˆæˆèŠ‚ç‚¹
    Basic zero-shot text-to-speech synthesis node for IndexTTS2
    
    Features:
    - Zero-shot speaker cloning with single audio prompt
    - High-quality speech synthesis
    - Support for multiple languages (Chinese, English)
    - Configurable output settings
    """
    
    def __init__(self):
        self.model = None
        self.model_config = None
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text": ("STRING", {
                    "multiline": True,
                    "default": "Hello, this is IndexTTS2 speaking!",
                    "placeholder": "è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬..."
                }),
                "speaker_audio": ("AUDIO", {
                    "tooltip": "è¿æ¥IndexTTS2 Load Audio FileèŠ‚ç‚¹ / Connect IndexTTS2 Load Audio File node"
                }),
                "output_filename": ("STRING", {
                    "default": "indextts2_output.wav",
                    "placeholder": "è¾“å‡ºéŸ³é¢‘æ–‡ä»¶å"
                }),
            },
            "optional": {
                "model_manager": ("INDEXTTS2_MODEL",),
                "language": (["auto", "zh", "en", "zh-en"], {
                    "default": "auto"
                }),
                "speed": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.5,
                    "max": 2.0,
                    "step": 0.1,
                    "display": "slider",
                    "tooltip": "è¯­é€Ÿæ§åˆ¶ (0.5-2.0å€é€Ÿ) / Speed control (0.5-2.0x)"
                }),
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.1,
                    "max": 1.5,
                    "step": 0.1,
                    "display": "slider"
                }),
                "top_p": ("FLOAT", {
                    "default": 0.9,
                    "min": 0.1,
                    "max": 1.0,
                    "step": 0.05,
                    "display": "slider"
                }),
                "use_fp16": ("BOOLEAN", {
                    "default": False
                }),
                "use_cuda_kernel": ("BOOLEAN", {
                    "default": False
                }),
                "verbose": ("BOOLEAN", {
                    "default": True
                }),
            }
        }
    
    RETURN_TYPES = ("AUDIO", "STRING", "STRING")
    RETURN_NAMES = ("audio", "output_path", "info")
    FUNCTION = "synthesize"
    CATEGORY = "IndexTTS2"
    DESCRIPTION = "Basic zero-shot text-to-speech synthesis using IndexTTS2"
    
    def synthesize(
        self,
        text: str,
        speaker_audio: dict,
        output_filename: str,
        model_manager: Optional[Any] = None,
        language: str = "auto",
        speed: float = 1.0,
        temperature: float = 0.7,
        top_p: float = 0.9,
        use_fp16: bool = False,
        use_cuda_kernel: bool = False,
        verbose: bool = True
    ) -> Tuple[dict, str, str]:
        # å‚æ•°éªŒè¯
        if not isinstance(speed, (int, float)):
            raise ValueError(f"speedå‚æ•°å¿…é¡»æ˜¯æ•°å­—ï¼Œæ”¶åˆ°: {type(speed).__name__} = {speed}")

        if isinstance(speed, str):
            raise ValueError(f"speedå‚æ•°ä¸èƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œæ”¶åˆ°: '{speed}'")

        speed = float(speed)  # ç¡®ä¿æ˜¯floatç±»å‹
        """
        æ‰§è¡ŒåŸºç¡€è¯­éŸ³åˆæˆ
        Perform basic text-to-speech synthesis
        """
        try:
            # éªŒè¯è¾“å…¥
            if not text.strip():
                raise ValueError("Text input cannot be empty")

            # å¤„ç†æ ‡å‡†ComfyUI AUDIOå¯¹è±¡
            if isinstance(speaker_audio, dict) and "waveform" in speaker_audio and "sample_rate" in speaker_audio:
                # è¿™æ˜¯æ ‡å‡†çš„ComfyUI AUDIOå¯¹è±¡
                # æˆ‘ä»¬éœ€è¦å°†å…¶ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ä¾›IndexTTS2ä½¿ç”¨
                import tempfile
                import torchaudio

                waveform = speaker_audio["waveform"]
                sample_rate = speaker_audio["sample_rate"]

                # ç§»é™¤batchç»´åº¦ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if waveform.dim() == 3:
                    waveform = waveform.squeeze(0)

                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                    speaker_audio_path = tmp_file.name

                # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
                torchaudio.save(speaker_audio_path, waveform, sample_rate)

                if verbose:
                    print(f"[IndexTTS2] ä½¿ç”¨ComfyUI AUDIOå¯¹è±¡ï¼Œä¸´æ—¶æ–‡ä»¶: {speaker_audio_path}")
                    print(f"[IndexTTS2] éŸ³é¢‘ä¿¡æ¯: é‡‡æ ·ç‡={sample_rate}, å½¢çŠ¶={waveform.shape}")
            else:
                raise ValueError("speaker_audio must be a ComfyUI AUDIO object with 'waveform' and 'sample_rate' keys")
            
            # è·å–æ¨¡å‹å®ä¾‹
            if model_manager is not None:
                model = model_manager
            else:
                model = self._load_default_model(use_fp16, use_cuda_kernel)
            
            # å‡†å¤‡è¾“å‡ºè·¯å¾„
            output_dir = folder_paths.get_output_directory()
            output_path = os.path.join(output_dir, output_filename)
            
            # æ‰§è¡Œæ¨ç†
            if verbose:
                print(f"[IndexTTS2] Synthesizing: {text[:50]}...")
                print(f"[IndexTTS2] Speaker audio: {speaker_audio_path}")
                print(f"[IndexTTS2] Output: {output_path}")

            # è°ƒç”¨IndexTTS2æ¨ç†ï¼Œä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°
            model.infer(
                spk_audio_prompt=speaker_audio_path,
                text=text,
                output_path=output_path,
                verbose=verbose,
                # æ·»åŠ æ¨ç†è´¨é‡å‚æ•°
                temperature=0.7,  # é™ä½æ¸©åº¦ä»¥æé«˜ç¨³å®šæ€§å’Œè´¨é‡
                top_p=0.9,        # ä½¿ç”¨nucleus sampling
                top_k=50,         # é™åˆ¶å€™é€‰tokenæ•°é‡
                max_text_tokens_per_sentence=120,  # é™åˆ¶æ¯å¥è¯çš„tokenæ•°é‡
                interval_silence=200  # å¥å­é—´çš„é™éŸ³é—´éš”(ms)
            )

            # åŠ è½½ç”Ÿæˆçš„éŸ³é¢‘
            audio_data = self._load_audio(output_path)

            # ç¡®ä¿éŸ³é¢‘æ ¼å¼å…¼å®¹ComfyUI
            waveform = audio_data["waveform"]
            sample_rate = audio_data["sample_rate"]

            # åº”ç”¨æœ€ç»ˆçš„ComfyUIå…¼å®¹æ€§æ£€æŸ¥
            from .audio_utils import fix_comfyui_audio_compatibility
            waveform = fix_comfyui_audio_compatibility(waveform)

            # ComfyUI AUDIOæ ¼å¼éœ€è¦ [batch, channels, samples]
            # æˆ‘ä»¬çš„waveformæ˜¯ [channels, samples]ï¼Œéœ€è¦æ·»åŠ batchç»´åº¦
            if waveform.dim() == 2:
                waveform = waveform.unsqueeze(0)  # [channels, samples] -> [1, channels, samples]

            # åˆ›å»ºComfyUI AUDIOæ ¼å¼ï¼ˆä¸LoadAudioèŠ‚ç‚¹ä¸€è‡´ï¼‰
            comfyui_audio = {
                "waveform": waveform,
                "sample_rate": sample_rate
            }

            print(f"[IndexTTS2] æœ€ç»ˆéŸ³é¢‘æ ¼å¼: {waveform.shape}, é‡‡æ ·ç‡: {sample_rate}")
            print(f"[IndexTTS2] ComfyUI AUDIOæ ¼å¼: batch={waveform.shape[0]}, channels={waveform.shape[1]}, samples={waveform.shape[2]}")

            # ç”Ÿæˆä¿¡æ¯å­—ç¬¦ä¸²
            info = self._generate_info(text, speaker_audio_path, output_path, language, speed)

            return (comfyui_audio, output_path, info)
            
        except Exception as e:
            error_msg = f"IndexTTS2 synthesis failed: {str(e)}"
            print(f"[IndexTTS2 Error] {error_msg}")
            raise RuntimeError(error_msg)
    
    def _load_default_model(self, use_fp16: bool, use_cuda_kernel: bool):
        """åŠ è½½é»˜è®¤æ¨¡å‹"""
        try:
            from indextts.infer_v2 import IndexTTS2

            # ä½¿ç”¨é€šç”¨æ¨¡å‹è·¯å¾„å‡½æ•°
            from .model_utils import get_indextts2_model_path, validate_model_path

            model_dir, config_path = get_indextts2_model_path()

            print(f"[IndexTTS2] ä½¿ç”¨æ¨¡å‹è·¯å¾„: {model_dir}")
            print(f"[IndexTTS2] Using model path: {model_dir}")

            # éªŒè¯æ¨¡å‹è·¯å¾„
            validate_model_path(model_dir, config_path)

            model = IndexTTS2(
                cfg_path=config_path,
                model_dir=model_dir,
                is_fp16=use_fp16,
                use_cuda_kernel=use_cuda_kernel
            )

            return model

        except Exception as e:
            error_msg = f"Failed to load IndexTTS2 model: {str(e)}"
            # ç‰¹åˆ«å¤„ç†DeepSpeedç›¸å…³é”™è¯¯
            if "deepspeed" in str(e).lower():
                error_msg += "\n[IndexTTS2] DeepSpeedç›¸å…³é”™è¯¯ï¼Œä½†åŸºæœ¬åŠŸèƒ½åº”è¯¥ä»ç„¶å¯ç”¨"
                error_msg += "\n[IndexTTS2] DeepSpeed-related error, but basic functionality should still work"
            raise RuntimeError(error_msg)
    
    def _load_audio(self, audio_path: str) -> dict:
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        from .audio_utils import load_audio_for_comfyui
        return load_audio_for_comfyui(audio_path)
    
    def _generate_info(self, text: str, speaker_audio: str, output_path: str,
                      language: str, speed: float) -> str:
        """ç”Ÿæˆä¿¡æ¯å­—ç¬¦ä¸²ï¼ŒåŒ…å«Qwenæ¨¡å‹ä¿¡æ¯"""
        info_lines = [
            "=== IndexTTS2 Basic Synthesis Info ===",
            f"Text: {text[:100]}{'...' if len(text) > 100 else ''}",
            f"Speaker Audio: {os.path.basename(speaker_audio)}",
            f"Output: {os.path.basename(output_path)}",
            f"Language: {language}",
            f"Speed: {speed}x",
            f"Model: IndexTTS2 Basic",
            "",
            "=== Qwen Emotion Model Status ===",
        ]

        # è·å–Qwenæ¨¡å‹çŠ¶æ€ä¿¡æ¯
        qwen_info = self._get_qwen_model_info()
        info_lines.extend(qwen_info)

        return "\n".join(info_lines)

    def _get_qwen_model_info(self) -> list:
        """è·å–å½“å‰Qwenæ¨¡å‹ä¿¡æ¯"""
        try:
            # æ£€æŸ¥transformersç‰ˆæœ¬
            import transformers
            from packaging import version

            current_version = transformers.__version__
            info_lines = [f"ğŸ”§ Transformersç‰ˆæœ¬: {current_version}"]

            # ç›´æ¥æ£€æŸ¥å…¼å®¹æ€§ï¼Œä¸åˆ›å»ºQwenEmotionå®ä¾‹
            compatible_models = self._get_compatible_qwen_models_direct()

            # æ˜¾ç¤ºå…¼å®¹æ¨¡å‹ä¿¡æ¯
            if compatible_models:
                best_model = compatible_models[0]  # ç¬¬ä¸€ä¸ªæ˜¯ä¼˜å…ˆçº§æœ€é«˜çš„
                info_lines.extend([
                    f"ğŸ¤– æ¨èæ¨¡å‹: {best_model['name']}",
                    f"ğŸ“Š æ¨¡å‹å¤§å°: {best_model['size']}",
                    f"ğŸ“ æ¨¡å‹ç±»å‹: æ™ºèƒ½é€‰æ‹©",
                    f"âœ… çŠ¶æ€: é«˜ç²¾åº¦æƒ…æ„Ÿåˆ†æå¯ç”¨"
                ])
            else:
                info_lines.extend([
                    f"ğŸ¤– æƒ…æ„Ÿæ¨¡å‹: å…³é”®è¯åŒ¹é…",
                    f"ğŸ“ æ¨¡å‹ç±»å‹: å¤‡ç”¨æ–¹æ¡ˆ",
                    f"âš ï¸  çŠ¶æ€: åŸºç¡€æƒ…æ„Ÿåˆ†æå¯ç”¨"
                ])

            # æ˜¾ç¤ºå…¼å®¹æ¨¡å‹æ•°é‡
            info_lines.append(f"ğŸ” å…¼å®¹Qwenæ¨¡å‹: {len(compatible_models)}ä¸ª")

            return info_lines

        except Exception as e:
            return [
                f"âŒ Qwenæ¨¡å‹ä¿¡æ¯è·å–å¤±è´¥: {str(e)[:50]}...",
                f"â„¹ï¸  åŸºæœ¬TTSåŠŸèƒ½ä¸å—å½±å“"
            ]

    def _get_compatible_qwen_models_direct(self):
        """ç›´æ¥è·å–å…¼å®¹çš„Qwenæ¨¡å‹åˆ—è¡¨ï¼Œä¸åˆ›å»ºQwenEmotionå®ä¾‹"""
        try:
            import transformers
            from packaging import version

            current_ver = version.parse(transformers.__version__)

            # å®šä¹‰ä¸åŒQwenæ¨¡å‹çš„ç‰ˆæœ¬è¦æ±‚å’Œä¼˜å…ˆçº§
            qwen_models = []

            # Qwen3ç³»åˆ— (éœ€è¦transformers >= 4.51.0)
            if current_ver >= version.parse("4.51.0"):
                qwen_models.extend([
                    {
                        "name": "Qwen3-0.5B-Instruct",
                        "model_id": "Qwen/Qwen3-0.5B-Instruct",
                        "priority": 1,
                        "size": "0.5B",
                        "description": "æœ€æ–°Qwen3æ¨¡å‹ï¼Œå°å‹é«˜æ•ˆ"
                    },
                    {
                        "name": "Qwen3-1.8B-Instruct",
                        "model_id": "Qwen/Qwen3-1.8B-Instruct",
                        "priority": 2,
                        "size": "1.8B",
                        "description": "Qwen3ä¸­å‹æ¨¡å‹"
                    }
                ])

            # Qwen2.5ç³»åˆ— (éœ€è¦transformers >= 4.37.0)
            if current_ver >= version.parse("4.37.0"):
                qwen_models.extend([
                    {
                        "name": "Qwen2.5-0.5B-Instruct",
                        "model_id": "Qwen/Qwen2.5-0.5B-Instruct",
                        "priority": 3,
                        "size": "0.5B",
                        "description": "Qwen2.5å°å‹æ¨¡å‹"
                    },
                    {
                        "name": "Qwen2.5-1.5B-Instruct",
                        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
                        "priority": 4,
                        "size": "1.5B",
                        "description": "Qwen2.5ä¸­å‹æ¨¡å‹"
                    }
                ])

            # Qwen2ç³»åˆ— (éœ€è¦transformers >= 4.37.0)
            if current_ver >= version.parse("4.37.0"):
                qwen_models.extend([
                    {
                        "name": "Qwen2-0.5B-Instruct",
                        "model_id": "Qwen/Qwen2-0.5B-Instruct",
                        "priority": 5,
                        "size": "0.5B",
                        "description": "Qwen2å°å‹æ¨¡å‹"
                    },
                    {
                        "name": "Qwen2-1.5B-Instruct",
                        "model_id": "Qwen/Qwen2-1.5B-Instruct",
                        "priority": 6,
                        "size": "1.5B",
                        "description": "Qwen2ä¸­å‹æ¨¡å‹"
                    }
                ])

            # Qwen1.5ç³»åˆ— (éœ€è¦transformers >= 4.37.0)
            if current_ver >= version.parse("4.37.0"):
                qwen_models.extend([
                    {
                        "name": "Qwen1.5-0.5B-Chat",
                        "model_id": "Qwen/Qwen1.5-0.5B-Chat",
                        "priority": 7,
                        "size": "0.5B",
                        "description": "Qwen1.5å°å‹æ¨¡å‹"
                    },
                    {
                        "name": "Qwen1.5-1.8B-Chat",
                        "model_id": "Qwen/Qwen1.5-1.8B-Chat",
                        "priority": 8,
                        "size": "1.8B",
                        "description": "Qwen1.5ä¸­å‹æ¨¡å‹"
                    }
                ])

            # æŒ‰ä¼˜å…ˆçº§æ’åº
            qwen_models.sort(key=lambda x: x["priority"])

            return qwen_models

        except Exception as e:
            print(f"[IndexTTS2] âš ï¸  è·å–å…¼å®¹æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            return []

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        """æ£€æŸ¥è¾“å…¥æ˜¯å¦æ”¹å˜"""
        return float("nan")  # æ€»æ˜¯é‡æ–°æ‰§è¡Œ
