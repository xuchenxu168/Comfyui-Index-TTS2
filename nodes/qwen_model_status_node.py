"""
IndexTTS2 Qwenæ¨¡å‹çŠ¶æ€èŠ‚ç‚¹
æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„Qwenæƒ…æ„Ÿåˆ†ææ¨¡å‹ä¿¡æ¯
"""

import os
import sys
import traceback
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).resolve().parent
project_root = current_dir.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

try:
    from indextts.infer_v2 import QwenEmotion
except ImportError as e:
    print(f"Failed to import QwenEmotion: {e}")
    QwenEmotion = None


class IndexTTS2QwenModelStatusNode:
    """
    IndexTTS2 Qwenæ¨¡å‹çŠ¶æ€èŠ‚ç‚¹
    æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„Qwenæƒ…æ„Ÿåˆ†ææ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {},
            "optional": {}
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("current_model", "model_status", "detailed_info")
    FUNCTION = "get_qwen_model_status"
    CATEGORY = "IndexTTS2"
    
    def get_qwen_model_status(self):
        """è·å–Qwenæ¨¡å‹çŠ¶æ€ä¿¡æ¯"""
        try:
            if QwenEmotion is None:
                return ("âŒ QwenEmotionç±»å¯¼å…¥å¤±è´¥", "âŒ å¯¼å…¥å¤±è´¥", "QwenEmotionç±»å¯¼å…¥å¤±è´¥")

            # ç›´æ¥æ£€æŸ¥å…¼å®¹æ€§ï¼Œä¸åˆ›å»ºQwenEmotionå®ä¾‹
            compatible_models = self._get_compatible_qwen_models_direct()

            # è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯ï¼ˆç®€æ´ç‰ˆï¼‰
            current_model = self._get_current_model_simple(compatible_models)

            # è·å–æ¨¡å‹çŠ¶æ€ï¼ˆç®€æ´ç‰ˆï¼‰
            model_status = self._get_model_status_simple(compatible_models)

            # è·å–è¯¦ç»†ä¿¡æ¯
            detailed_info = self._get_detailed_info()

            return (current_model, model_status, detailed_info)

        except Exception as e:
            error_msg = f"è·å–Qwenæ¨¡å‹çŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            return ("âŒ é”™è¯¯", "âŒ çŠ¶æ€è·å–å¤±è´¥", error_msg)

    def _get_current_model_simple(self, compatible_models) -> str:
        """è·å–å½“å‰æ¨¡å‹çš„ç®€æ´ä¿¡æ¯"""
        try:
            import transformers
            current_version = transformers.__version__

            if compatible_models:
                best_model = compatible_models[0]  # ç¬¬ä¸€ä¸ªæ˜¯ä¼˜å…ˆçº§æœ€é«˜çš„
                return f"ğŸ¤– {best_model['name']} ({best_model['size']}) | Transformers {current_version}"
            else:
                return f"ğŸ”¤ å…³é”®è¯åŒ¹é…å¤‡ç”¨æ–¹æ¡ˆ | Transformers {current_version}"

        except Exception as e:
            return f"âŒ æ¨¡å‹ä¿¡æ¯è·å–å¤±è´¥: {str(e)[:30]}..."

    def _get_model_status_simple(self, compatible_models) -> str:
        """è·å–æ¨¡å‹çŠ¶æ€çš„ç®€æ´ä¿¡æ¯"""
        try:
            if compatible_models:
                return "âœ… Qwenæ¨¡å‹å¯ç”¨"
            else:
                return "âš ï¸  å…³é”®è¯åŒ¹é…æ¨¡å¼"

        except Exception as e:
            return f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥"

    def _get_detailed_info(self) -> str:
        """è·å–è¯¦ç»†ä¿¡æ¯"""
        try:
            status_info = []
            status_info.append("=" * 60)
            status_info.append("IndexTTS2 Qwenæƒ…æ„Ÿåˆ†ææ¨¡å‹è¯¦ç»†çŠ¶æ€")
            status_info.append("IndexTTS2 Qwen Emotion Analysis Model Detailed Status")
            status_info.append("=" * 60)

            # æ£€æŸ¥transformersç‰ˆæœ¬
            try:
                import transformers
                from packaging import version

                current_version = transformers.__version__
                status_info.append(f"ğŸ“¦ Transformersç‰ˆæœ¬: {current_version}")
                status_info.append(f"ğŸ“¦ Transformers Version: {current_version}")

                # è·å–å…¼å®¹çš„æ¨¡å‹åˆ—è¡¨
                compatible_models = self._get_compatible_qwen_models_direct()
                status_info.append(f"ğŸ” å…¼å®¹æ¨¡å‹æ•°é‡: {len(compatible_models)}")
                status_info.append(f"ğŸ” Compatible Models Count: {len(compatible_models)}")

                if compatible_models:
                    status_info.append("\nğŸ“‹ å…¼å®¹çš„Qwenæ¨¡å‹åˆ—è¡¨:")
                    status_info.append("ğŸ“‹ Compatible Qwen Models List:")
                    for i, model in enumerate(compatible_models[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                        status_info.append(f"  {i}. {model['name']} ({model['size']}) - {model['description']}")

                    if len(compatible_models) > 5:
                        status_info.append(f"  ... è¿˜æœ‰ {len(compatible_models) - 5} ä¸ªæ¨¡å‹")
                        status_info.append(f"  ... and {len(compatible_models) - 5} more models")

            except ImportError:
                status_info.append("âŒ Transformersæœªå®‰è£…")
                status_info.append("âŒ Transformers not installed")
            except Exception as e:
                status_info.append(f"âš ï¸  ç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}")
                status_info.append(f"âš ï¸  Version check failed: {e}")

            # æ£€æŸ¥å½“å‰æ¨¡å‹çŠ¶æ€
            status_info.append("\nğŸ¤– å½“å‰æ¨¡å‹çŠ¶æ€:")
            status_info.append("ğŸ¤– Current Model Status:")

            if temp_qwen.is_available:
                if hasattr(temp_qwen, 'fallback_model_info'):
                    model_info = temp_qwen.fallback_model_info
                    status_info.append(f"âœ… ä½¿ç”¨å¤‡ç”¨æ¨¡å‹: {model_info['name']}")
                    status_info.append(f"âœ… Using fallback model: {model_info['name']}")
                    status_info.append(f"ğŸ“Š æ¨¡å‹å¤§å°: {model_info['size']}")
                    status_info.append(f"ğŸ“Š Model size: {model_info['size']}")
                    status_info.append(f"ğŸ“ æè¿°: {model_info['description']}")
                    status_info.append(f"ğŸ“ Description: {model_info['description']}")
                else:
                    status_info.append("âœ… ä½¿ç”¨åŸå§‹Qwenæ¨¡å‹")
                    status_info.append("âœ… Using original Qwen model")
            else:
                status_info.append("âš ï¸  Qwenæ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…")
                status_info.append("âš ï¸  Qwen model unavailable, using keyword matching")

            # åŠŸèƒ½çŠ¶æ€
            status_info.append("\nğŸ”§ åŠŸèƒ½çŠ¶æ€:")
            status_info.append("ğŸ”§ Functionality Status:")

            if temp_qwen.is_available:
                status_info.append("âœ… é«˜ç²¾åº¦æƒ…æ„Ÿåˆ†æ: å¯ç”¨")
                status_info.append("âœ… High-precision emotion analysis: Available")
            else:
                status_info.append("âš ï¸  é«˜ç²¾åº¦æƒ…æ„Ÿåˆ†æ: ä¸å¯ç”¨")
                status_info.append("âš ï¸  High-precision emotion analysis: Unavailable")

            status_info.append("âœ… å…³é”®è¯åŒ¹é…å¤‡ç”¨æ–¹æ¡ˆ: å§‹ç»ˆå¯ç”¨")
            status_info.append("âœ… Keyword matching fallback: Always available")
            status_info.append("âœ… IndexTTS2åŸºæœ¬åŠŸèƒ½: ä¸å—å½±å“")
            status_info.append("âœ… IndexTTS2 basic functionality: Unaffected")

            # å»ºè®®
            status_info.append("\nğŸ’¡ å»ºè®®:")
            status_info.append("ğŸ’¡ Recommendations:")

            if not temp_qwen.is_available:
                status_info.append("ğŸ”§ è€ƒè™‘æ›´æ–°transformersä»¥è·å¾—æ›´å¥½çš„æƒ…æ„Ÿåˆ†æ")
                status_info.append("ğŸ”§ Consider updating transformers for better emotion analysis")
                status_info.append("ğŸ“ å‘½ä»¤: pip install --upgrade transformers")
                status_info.append("ğŸ“ Command: pip install --upgrade transformers")
            else:
                status_info.append("âœ… å½“å‰é…ç½®è‰¯å¥½ï¼Œæ— éœ€é¢å¤–æ“ä½œ")
                status_info.append("âœ… Current configuration is good, no additional action needed")

            status_info.append("=" * 60)

            return "\n".join(status_info)

        except Exception as e:
            return f"è·å–è¯¦ç»†ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

    def _get_compatible_qwen_models_direct(self):
        """ç›´æ¥è·å–å…¼å®¹çš„Qwenæ¨¡å‹åˆ—è¡¨ï¼Œä¸åˆ›å»ºQwenEmotionå®ä¾‹"""
        try:
            import transformers
            from packaging import version

            current_ver = version.parse(transformers.__version__)

            # å®šä¹‰ä¸åŒQwenæ¨¡å‹çš„ç‰ˆæœ¬è¦æ±‚å’Œä¼˜å…ˆçº§
            qwen_models = []

            # Qwen3ç³»åˆ— (éœ€è¦transformers >= 4.51.0)
            if current_ver >= version.parse("4.51.0"):
                qwen_models.extend([
                    {
                        "name": "Qwen3-0.5B-Instruct",
                        "model_id": "Qwen/Qwen3-0.5B-Instruct",
                        "priority": 1,
                        "size": "0.5B",
                        "description": "æœ€æ–°Qwen3æ¨¡å‹ï¼Œå°å‹é«˜æ•ˆ"
                    },
                    {
                        "name": "Qwen3-1.8B-Instruct",
                        "model_id": "Qwen/Qwen3-1.8B-Instruct",
                        "priority": 2,
                        "size": "1.8B",
                        "description": "Qwen3ä¸­å‹æ¨¡å‹"
                    }
                ])

            # Qwen2.5ç³»åˆ— (éœ€è¦transformers >= 4.37.0)
            if current_ver >= version.parse("4.37.0"):
                qwen_models.extend([
                    {
                        "name": "Qwen2.5-0.5B-Instruct",
                        "model_id": "Qwen/Qwen2.5-0.5B-Instruct",
                        "priority": 3,
                        "size": "0.5B",
                        "description": "Qwen2.5å°å‹æ¨¡å‹"
                    },
                    {
                        "name": "Qwen2.5-1.5B-Instruct",
                        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
                        "priority": 4,
                        "size": "1.5B",
                        "description": "Qwen2.5ä¸­å‹æ¨¡å‹"
                    }
                ])

            # Qwen2ç³»åˆ— (éœ€è¦transformers >= 4.37.0)
            if current_ver >= version.parse("4.37.0"):
                qwen_models.extend([
                    {
                        "name": "Qwen2-0.5B-Instruct",
                        "model_id": "Qwen/Qwen2-0.5B-Instruct",
                        "priority": 5,
                        "size": "0.5B",
                        "description": "Qwen2å°å‹æ¨¡å‹"
                    },
                    {
                        "name": "Qwen2-1.5B-Instruct",
                        "model_id": "Qwen/Qwen2-1.5B-Instruct",
                        "priority": 6,
                        "size": "1.5B",
                        "description": "Qwen2ä¸­å‹æ¨¡å‹"
                    }
                ])

            # Qwen1.5ç³»åˆ— (éœ€è¦transformers >= 4.37.0)
            if current_ver >= version.parse("4.37.0"):
                qwen_models.extend([
                    {
                        "name": "Qwen1.5-0.5B-Chat",
                        "model_id": "Qwen/Qwen1.5-0.5B-Chat",
                        "priority": 7,
                        "size": "0.5B",
                        "description": "Qwen1.5å°å‹æ¨¡å‹"
                    },
                    {
                        "name": "Qwen1.5-1.8B-Chat",
                        "model_id": "Qwen/Qwen1.5-1.8B-Chat",
                        "priority": 8,
                        "size": "1.8B",
                        "description": "Qwen1.5ä¸­å‹æ¨¡å‹"
                    }
                ])

            # æŒ‰ä¼˜å…ˆçº§æ’åº
            qwen_models.sort(key=lambda x: x["priority"])

            return qwen_models

        except Exception as e:
            print(f"[IndexTTS2] âš ï¸  è·å–å…¼å®¹æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            return []


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "IndexTTS2_QwenModelStatus": IndexTTS2QwenModelStatusNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "IndexTTS2_QwenModelStatus": "IndexTTS2 Qwen Model Status"
}
